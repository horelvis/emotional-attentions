{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f545df4",
   "metadata": {},
   "source": [
    "# Emotional Attention (Dual-Head) con **propagación afectiva**\n",
    "\n",
    "Notebook listo para **Google Colab**. Entrena un mini decoder con **Atención Emocional** para **aprender**\n",
    "a responder con tono emocional derivado de la entrada (no clasifica). Incluye:\n",
    "- Capa **Dual-Head Emotional Attention + Gating** en el bloque Transformer.\n",
    "- Señales de entrenamiento **sin etiquetas**: *LM + propagación* entrada→salida y **distil latente opcional** con teacher congelado.\n",
    "- Generación condicionada por el **estado emocional inferido** del input.\n",
    "- Evaluación por **alineación intrínseca** (coseno entre emoción de entrada y emoción de salida generada).\n",
    "\n",
    "⚠️ Es un POC mínimo con dataset pequeño. Reemplaza por tus pares (input→respuesta) para resultados reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b292b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Instalación mínima sin conflictos (reinicio limpio recomendado)\n",
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_NO_TORCHVISION\"] = \"1\"\n",
    "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
    "\n",
    "# Limpia paquetes conflictivos\n",
    "%pip uninstall -y -q pysentimiento accelerate transformers tokenizers huggingface_hub safetensors peft\n",
    "\n",
    "# Set estable para este notebook\n",
    "%pip install -q \"transformers==4.41.2\" \"safetensors==0.4.2\"\n",
    "\n",
    "import transformers, torch, sys\n",
    "print(\"transformers:\", transformers.__version__, \"| python:\", sys.version)\n",
    "\n",
    "# Reinicia runtime para entorno limpio\n",
    "import os; os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "import math, random\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17e43ca",
   "metadata": {},
   "source": [
    "## Dataset mini (pares input→respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859312b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Datos y utilidades\n",
    "vocab = ['<pad>', '<bos>', '<eos>', '<sep>',\n",
    "         'te','quiero','mamá','hola','cariño','yo','tambien','estoy','triste','lo','siento','aqui','estoy2',\n",
    "         'no','odio','mucho','calma','hablemos','por','favor','feliz','me','alegra','porque']\n",
    "\n",
    "stoi = {w:i for i,w in enumerate(vocab)}\n",
    "itos = {i:w for w,i in stoi.items()}\n",
    "\n",
    "def encode(words: List[str]):\n",
    "    return [stoi[w] for w in words]\n",
    "\n",
    "pairs = [\n",
    "    (['te','quiero','mamá'],                 ['yo','tambien','te','quiero']),\n",
    "    (['hola','mamá'],                        ['hola','cariño']),\n",
    "    (['estoy','triste'],                     ['lo','siento','aqui','estoy2']),\n",
    "    (['no','te','quiero'],                   ['lo','siento','hablemos']),\n",
    "    (['te','odio','mucho'],                  ['calma','hablemos','por','favor']),\n",
    "    (['feliz'],                              ['me','alegra','mucho']),\n",
    "]\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(pairs)\n",
    "split = int(0.7*len(pairs))\n",
    "train_pairs = pairs[:split]\n",
    "valid_pairs = pairs[split:]\n",
    "\n",
    "def build_batch(pairs):\n",
    "    Xs, pad_masks, in_masks, out_masks = [], [], [], []\n",
    "    for inp, out in pairs:\n",
    "        ids = [stoi['<bos>']] + encode(inp) + [stoi['<sep>']] + encode(out) + [stoi['<eos>']]\n",
    "        Xs.append(ids)\n",
    "    maxlen = max(len(x) for x in Xs)\n",
    "    for i, ids in enumerate(Xs):\n",
    "        pad = [stoi['<pad>']] * (maxlen - len(ids))\n",
    "        Xs[i] = ids + pad\n",
    "        pad_masks.append([0]*len(ids) + [1]*len(pad))\n",
    "        in_mask = [0]*maxlen\n",
    "        out_mask = [0]*maxlen\n",
    "        if stoi['<sep>'] in ids:\n",
    "            sep_pos = ids.index(stoi['<sep>'])\n",
    "        else:\n",
    "            sep_pos = 1\n",
    "        for t in range(0, sep_pos): in_mask[t] = 1\n",
    "        for t in range(sep_pos+1, len(ids)):\n",
    "            if ids[t] != stoi['<pad>']: out_mask[t] = 1\n",
    "        in_masks.append(in_mask)\n",
    "        out_masks.append(out_mask)\n",
    "    X = torch.tensor(Xs, device=device)\n",
    "    PM = torch.tensor(pad_masks, device=device).bool()\n",
    "    INM = torch.tensor(in_masks, device=device).bool()\n",
    "    OUTM = torch.tensor(out_masks, device=device).bool()\n",
    "    return X, PM, INM, OUTM\n",
    "\n",
    "Xtr, Mtr, INtr, OUTtr = build_batch(train_pairs)\n",
    "Xva, Mva, INva, OUTva = build_batch(valid_pairs)\n",
    "\n",
    "print('Train batch:', Xtr.shape, 'Valid batch:', Xva.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80098f0f",
   "metadata": {},
   "source": [
    "## Teacher congelado (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc261c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Cargar Teacher HF (opcional)\n",
    "USE_DISTIL = True  # pon a False si no quieres distil\n",
    "\n",
    "HF_NAME = \"pysentimiento/robertuito-sentiment-analysis\"\n",
    "tok_teacher = AutoTokenizer.from_pretrained(HF_NAME, use_fast=True)\n",
    "teacher = AutoModel.from_pretrained(HF_NAME).to(device)\n",
    "for p in teacher.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "d_emo = 64\n",
    "teacher_proj = nn.Sequential(\n",
    "    nn.Linear(teacher.config.hidden_size, teacher.config.hidden_size),\n",
    "    nn.GELU(),\n",
    "    nn.Linear(teacher.config.hidden_size, d_emo),\n",
    ").to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def teacher_vec(words: List[str]) -> torch.Tensor:\n",
    "    text = \" \".join(words)\n",
    "    enc = tok_teacher(text, return_tensors='pt', truncation=True, max_length=128).to(device)\n",
    "    hs = teacher(**enc).last_hidden_state\n",
    "    h_pool = hs.mean(dim=1)\n",
    "    g_hat = teacher_proj(h_pool)[0]\n",
    "    return g_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d238904",
   "metadata": {},
   "source": [
    "## Bloque Emotional Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db098283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Implementación del bloque dual\n",
    "def _shape(x, B, T, n_heads, d_head):\n",
    "    return x.view(B, T, n_heads, d_head).transpose(1, 2)\n",
    "\n",
    "class MultiHeadSelfAttn(nn.Module):\n",
    "    def __init__(self, d_model: int, n_heads: int):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        self.nh = n_heads; self.dh = d_model // n_heads\n",
    "        self.q = nn.Linear(d_model, d_model)\n",
    "        self.k = nn.Linear(d_model, d_model)\n",
    "        self.v = nn.Linear(d_model, d_model)\n",
    "        self.o = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, H, key_padding_mask=None, causal=True, return_attn=False):\n",
    "        B, T, D = H.shape\n",
    "        q = _shape(self.q(H), B, T, self.nh, self.dh)\n",
    "        k = _shape(self.k(H), B, T, self.nh, self.dh)\n",
    "        v = _shape(self.v(H), B, T, self.nh, self.dh)\n",
    "        scores = (q @ k.transpose(-2,-1)) / math.sqrt(self.dh)\n",
    "        if causal:\n",
    "            idx = torch.arange(T, device=H.device)\n",
    "            causal_mask = (idx[None, :] <= idx[:, None]).float()\n",
    "            scores = scores + (causal_mask[None, None, :, :] - 1) * 1e9\n",
    "        if key_padding_mask is not None:\n",
    "            mask = key_padding_mask[:, None, None, :].bool()\n",
    "            scores = scores.masked_fill(mask, float('-inf'))\n",
    "        A = torch.softmax(scores, dim=-1)\n",
    "        O = (A @ v).transpose(1,2).contiguous().view(B,T,D)\n",
    "        O = self.o(O)\n",
    "        return (O, A) if return_attn else (O, None)\n",
    "\n",
    "class DualHeadEmoAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, n_heads: int, d_emo: int, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.sem = MultiHeadSelfAttn(d_model, n_heads)\n",
    "        self.proj_u = nn.Linear(d_emo, d_model)\n",
    "        self.emo = MultiHeadSelfAttn(d_model, n_heads)\n",
    "        self.Wg_h = nn.Linear(d_model, d_model)\n",
    "        self.Wg_e = nn.Linear(d_model, d_model)\n",
    "        self.Wg_g = nn.Linear(d_model, d_model)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, H, U, g, key_padding_mask=None, return_attn=False):\n",
    "        O_sem, A_sem = self.sem(H, key_padding_mask=key_padding_mask, causal=True, return_attn=True)\n",
    "        U_proj = self.proj_u(U)\n",
    "        O_emo, A_emo = self.emo(U_proj, key_padding_mask=key_padding_mask, causal=True, return_attn=True)\n",
    "        g_proj = self.Wg_g(self.proj_u(g)).expand(H.size(0), H.size(1), -1)\n",
    "        G = torch.sigmoid(self.Wg_h(O_sem) + self.Wg_e(O_emo) + g_proj)\n",
    "        mix = (1-G)*O_sem + G*O_emo\n",
    "        out = self.norm(self.out(self.drop(mix)) + H)\n",
    "        if return_attn:\n",
    "            return out, {'A_sem':A_sem, 'A_emo':A_emo, 'G':G}\n",
    "        return out, None\n",
    "\n",
    "class EmoBlock(nn.Module):\n",
    "    def __init__(self, d_model=256, n_heads=8, mlp_ratio=2.0, d_emo=64):\n",
    "        super().__init__()\n",
    "        self.dual = DualHeadEmoAttention(d_model, n_heads, d_emo)\n",
    "        self.pre = nn.LayerNorm(d_model)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, int(mlp_ratio*d_model)),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(int(mlp_ratio*d_model), d_model),\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, H, U, g, key_padding_mask=None, return_attn=False):\n",
    "        H1, attn = self.dual(H, U, g, key_padding_mask=key_padding_mask, return_attn=True)\n",
    "        H2 = self.norm(self.mlp(self.pre(H1)) + H1)\n",
    "        return (H2, attn) if return_attn else (H2, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af010b2a",
   "metadata": {},
   "source": [
    "## Modelo completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ab2b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Decoder emocional\n",
    "class EmoDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=256, n_heads=8, d_emo=64, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.tok = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos = nn.Embedding(512, d_model)\n",
    "        self.blocks = nn.ModuleList([EmoBlock(d_model, n_heads, mlp_ratio=2.0, d_emo=d_emo) for _ in range(n_layers)])\n",
    "        self.lm_head = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        self.emo_in_head  = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, d_emo))\n",
    "        self.emo_out_head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, d_emo))\n",
    "        self.u_head = nn.Linear(d_model, d_emo)\n",
    "\n",
    "    def forward(self, X, pad_mask, in_mask, out_mask, return_attn=False):\n",
    "        B, T = X.shape\n",
    "        pos = torch.arange(T, device=X.device)[None, :].expand(B, T)\n",
    "        H = self.tok(X) + self.pos(pos)\n",
    "\n",
    "        H_in = H.masked_fill(~in_mask[...,None], 0.0)\n",
    "        denom_in = in_mask.sum(1).clamp(min=1).view(B,1).float()\n",
    "        H_in_pool = H_in.sum(1) / denom_in\n",
    "        g_in = self.emo_in_head(H_in_pool).unsqueeze(1)   # (B,1,d_emo)\n",
    "\n",
    "        U = self.u_head(H)\n",
    "\n",
    "        attn_last = None\n",
    "        for blk in self.blocks:\n",
    "            H, attn = blk(H, U, g_in, key_padding_mask=pad_mask, return_attn=True)\n",
    "            U = self.u_head(H)\n",
    "            attn_last = attn\n",
    "\n",
    "        logits = self.lm_head(H)\n",
    "\n",
    "        H_out = H.masked_fill(~out_mask[...,None], 0.0)\n",
    "        denom_out = out_mask.sum(1).clamp(min=1).view(B,1).float()\n",
    "        H_out_pool = H_out.sum(1) / denom_out\n",
    "        g_out = self.emo_out_head(H_out_pool)             # (B,d_emo)\n",
    "\n",
    "        if return_attn:\n",
    "            return logits, g_in.squeeze(1), g_out, attn_last\n",
    "        return logits, g_in.squeeze(1), g_out, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe84ee63",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e0b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Entrenar (LM + propagación + distil opcional)\n",
    "d_model, d_emo, n_heads, n_layers = 256, 64, 8, 2\n",
    "model = EmoDecoder(len(vocab), d_model=d_model, n_heads=n_heads, d_emo=d_emo, n_layers=n_layers).to(device)\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
    "def shift_targets(X): return torch.roll(X, shifts=-1, dims=1)\n",
    "targets_tr = shift_targets(Xtr); targets_va = shift_targets(Xva)\n",
    "\n",
    "lambda_prop, lambda_distil, lambda_sparse = 0.5, 0.3, 1e-4\n",
    "\n",
    "def cosine_loss(a, b):\n",
    "    a = F.normalize(a, dim=-1); b = F.normalize(b, dim=-1)\n",
    "    return (1 - (a*b).sum(-1)).mean()\n",
    "\n",
    "for ep in range(50):\n",
    "    model.train(); opt.zero_grad()\n",
    "    logits, g_in, g_out, attn = model(Xtr, Mtr, INtr, OUTtr, return_attn=True)\n",
    "    L_lm = F.cross_entropy(logits.view(-1, logits.size(-1)), targets_tr.view(-1), ignore_index=stoi['<pad>'])\n",
    "    L_prop = cosine_loss(g_in, g_out)\n",
    "\n",
    "    if USE_DISTIL:\n",
    "        g_in_hat_list, g_out_hat_list = [], []\n",
    "        for (inp, out) in train_pairs:\n",
    "            g_in_hat_list.append(teacher_vec(inp))\n",
    "            g_out_hat_list.append(teacher_vec(out))\n",
    "        g_in_hat  = torch.stack(g_in_hat_list,  dim=0).to(device)\n",
    "        g_out_hat = torch.stack(g_out_hat_list, dim=0).to(device)\n",
    "        L_distil = F.mse_loss(g_in, g_in_hat) + F.mse_loss(g_out, g_out_hat)\n",
    "    else:\n",
    "        L_distil = torch.tensor(0.0, device=device)\n",
    "\n",
    "    A_emo = attn['A_emo']\n",
    "    L_sparse = A_emo.abs().mean()\n",
    "\n",
    "    loss = L_lm + lambda_prop*L_prop + lambda_distil*L_distil + lambda_sparse*L_sparse\n",
    "    loss.backward(); opt.step()\n",
    "\n",
    "    if (ep+1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            logits_v, gi_v, go_v, _ = model(Xva, Mva, INva, OUTva, return_attn=False)\n",
    "            L_lm_v = F.cross_entropy(logits_v.view(-1, logits_v.size(-1)),\n",
    "                                     shift_targets(Xva).view(-1),\n",
    "                                     ignore_index=stoi['<pad>']).item()\n",
    "            L_prop_v = cosine_loss(gi_v, go_v).item()\n",
    "            ppl = math.exp(min(10, L_lm_v))\n",
    "        print(f\"Ep{ep+1:02d} | L={loss.item():.3f} | LM={L_lm.item():.3f} | PROP={L_prop.item():.3f} | DISTIL={L_distil.item():.3f} | PPL={ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f035c55",
   "metadata": {},
   "source": [
    "## Generación condicionada por g_in (entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae29486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Generate con top-k y EMA\n",
    "def sample_topk(logits_row, k=5, temp=0.9):\n",
    "    probs = F.softmax(logits_row / temp, dim=-1)\n",
    "    topk = torch.topk(probs, k)\n",
    "    idx = torch.multinomial(topk.values, 1)\n",
    "    return topk.indices[idx].item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_g_in_from_words(words: List[str]):\n",
    "    ids = [stoi['<bos>']] + encode(words) + [stoi['<sep>']]\n",
    "    X = torch.tensor([ids], device=device)\n",
    "    pad = torch.zeros_like(X).bool()\n",
    "    in_mask = torch.zeros_like(X).bool(); in_mask[:, :len(ids)-1] = True\n",
    "    out_mask = torch.zeros_like(X).bool()\n",
    "    _, g_in, _, _ = model(X, pad, in_mask, out_mask, return_attn=True)\n",
    "    return g_in.unsqueeze(1)  # (1,1,d_emo)\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_response(input_words: List[str], max_new=12, k=5, temp=0.9, ema_alpha=0.15):\n",
    "    ids = [stoi['<bos>']] + encode(input_words) + [stoi['<sep>']]\n",
    "    X = torch.tensor([ids], device=device)\n",
    "\n",
    "    def make_masks(X):\n",
    "        B, T = X.shape\n",
    "        pad = torch.zeros_like(X).bool()\n",
    "        in_mask = torch.zeros_like(X).bool()\n",
    "        out_mask = torch.zeros_like(X).bool()\n",
    "        if stoi['<sep>'] in X[0].tolist():\n",
    "            sep_pos = X[0].tolist().index(stoi['<sep>'])\n",
    "        else:\n",
    "            sep_pos = max(1, T-1)\n",
    "        in_mask[:, :sep_pos] = True\n",
    "        out_mask[:, sep_pos+1:] = True\n",
    "        return pad, in_mask, out_mask\n",
    "\n",
    "    g_t = infer_g_in_from_words(input_words)\n",
    "\n",
    "    for _ in range(max_new):\n",
    "        pad, in_mask, out_mask = make_masks(X)\n",
    "        logits, _, _, _ = model(X, pad, in_mask, out_mask, return_attn=False)\n",
    "        next_id = sample_topk(logits[0, -1], k=k, temp=temp)\n",
    "        X = torch.cat([X, torch.tensor([[next_id]], device=device)], dim=1)\n",
    "        if next_id == stoi['<eos>']:\n",
    "            break\n",
    "        pad, in_mask, out_mask = make_masks(X)\n",
    "        _, _, g_out_step, _ = model(X, pad, in_mask, out_mask, return_attn=False)\n",
    "        g_t = (1-ema_alpha)*g_t + ema_alpha*g_out_step.unsqueeze(1)\n",
    "    return X[0].tolist()\n",
    "\n",
    "def decode(ids):\n",
    "    return ' '.join(itos[int(i)] for i in ids if itos[int(i)] not in ['<pad>','<bos>'])\n",
    "\n",
    "for inp, _ in valid_pairs:\n",
    "    gen_ids = generate_response(inp, max_new=10, k=5, temp=0.9)\n",
    "    print('IN :', ' '.join(inp))\n",
    "    print('OUT:', decode(gen_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef62933",
   "metadata": {},
   "source": [
    "## Evaluación intrínseca (coseno entrada→salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2311bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Alineación emocional\n",
    "@torch.no_grad()\n",
    "def emo_alignment_score(input_words: List[str], gen_ids: List[int]):\n",
    "    g_in = infer_g_in_from_words(input_words).squeeze(0).squeeze(0)\n",
    "    toks = gen_ids\n",
    "    if stoi['<sep>'] in toks:\n",
    "        start = toks.index(stoi['<sep>'])+1\n",
    "    else:\n",
    "        start = max(1, len(toks)//2)\n",
    "    if stoi['<eos>'] in toks:\n",
    "        end = toks.index(stoi['<eos>'])+1\n",
    "    else:\n",
    "        end = len(toks)\n",
    "    X = torch.tensor([toks[:end]], device=device)\n",
    "    pad = torch.zeros_like(X).bool()\n",
    "    in_mask = torch.zeros_like(X).bool()\n",
    "    out_mask = torch.zeros_like(X).bool(); out_mask[:, start:end] = True\n",
    "    _, _, g_out, _ = model(X, pad, in_mask, out_mask, return_attn=False)\n",
    "    gi = F.normalize(g_in, dim=-1)\n",
    "    go = F.normalize(g_out, dim=-1)\n",
    "    return float(torch.dot(gi, go).clamp(-1,1))\n",
    "\n",
    "rows = []; scores = []\n",
    "for inp, _ in valid_pairs:\n",
    "    gen_ids = generate_response(inp, max_new=12, k=5, temp=0.9)\n",
    "    score = emo_alignment_score(inp, gen_ids)\n",
    "    rows.append((inp, decode(gen_ids), round(score,3)))\n",
    "    scores.append(score)\n",
    "print('Alineación media (coseno):', round(float(torch.tensor(scores).mean()),3))\n",
    "for r in rows:\n",
    "    print('IN :', ' '.join(r[0]))\n",
    "    print('OUT:', r[1])\n",
    "    print('COS:', r[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adde191",
   "metadata": {},
   "source": [
    "## Visualización de la atención emocional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b93f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Heatmaps\n",
    "@torch.no_grad()\n",
    "def visualize_attention(example_idx=0):\n",
    "    inp, out = valid_pairs[example_idx]\n",
    "    ids = [stoi['<bos>']] + encode(inp) + [stoi['<sep>']] + encode(out) + [stoi['<eos>']]\n",
    "    X = torch.tensor([ids], device=device)\n",
    "    pad = torch.zeros_like(X).bool()\n",
    "    in_mask = torch.zeros_like(X).bool()\n",
    "    sep_pos = ids.index(stoi['<sep>'])\n",
    "    in_mask[:, :sep_pos] = True\n",
    "    out_mask = torch.zeros_like(X).bool(); out_mask[:, sep_pos+1:] = True\n",
    "    _, _, _, attn = model(X, pad, in_mask, out_mask, return_attn=True)\n",
    "    A_sem = attn['A_sem'][0].mean(0).cpu()\n",
    "    A_emo = attn['A_emo'][0].mean(0).cpu()\n",
    "\n",
    "    toks = [itos[i] for i in ids]\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, axes = plt.subplots(1,2, figsize=(10,4))\n",
    "    im0 = axes[0].imshow(A_sem, aspect='auto'); axes[0].set_title('Atención SEM')\n",
    "    axes[0].set_xticks(range(len(toks))); axes[0].set_xticklabels(toks, rotation=45, ha='right')\n",
    "    axes[0].set_yticks(range(len(toks))); axes[0].set_yticklabels(toks); plt.colorbar(im0, ax=axes[0])\n",
    "    im1 = axes[1].imshow(A_emo, aspect='auto'); axes[1].set_title('Atención EMO')\n",
    "    axes[1].set_xticks(range(len(toks))); axes[1].set_xticklabels(toks, rotation=45, ha='right')\n",
    "    axes[1].set_yticks(range(len(toks))); axes[1].set_yticklabels(toks); plt.colorbar(im1, ax=axes[1])\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "visualize_attention(0)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
